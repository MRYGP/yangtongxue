# Human Capability Construction and Cognitive Resilience in the AI Era: A Theory of Cognitive Endosymbiosis Based on the Antifragility Validation Principle

    **Author**: Yang Guoping

    **Email**: a44425874@gmail.com

    **Version**: v1.0

    **Date**: October 2025

## Abstract

    Large language models and other AI tools are profoundly reshaping human work practices, yet their long-term impact on independent capabilities remains unclear. This study proposes the Cognitive Endosymbiosis Theory (CET), which measures whether independent capabilities are enhanced or degraded by AI assistance through the "Antifragility Validation Principle" (AVP). The research establishes a five-anchor measurement framework (B1-B5) and proposes design principles through the "Endosymbiotic Minimal Law" (EML), which promotes capability internalization via beneficial friction (50$\text{–}$70% success rate, working assumption) and systematic support reduction (S4$\rightarrow$S1$\rightarrow$S0). The core criterion: $P_2 \geq B_0 + \delta$ (post-unplugged capability must exceed baseline). The theory presents eight falsifiable hypotheses, explicitly defines applicability boundaries, and commits to open science validation (see Appendix B; Section 3.0 anchor texts).

    **Keywords**: Cognitive Endosymbiosis; Cognitive Exoskeleton; Antifragility Validation; Beneficial Cognitive Friction; Human-AI Collaboration; Cognitive Sustainability

## Table of Contents

    **Chapter 1: Introduction and Theoretical Positioning**

    - 1.1 Core Proposition: A New Standard for Evaluating AI
    - 1.2 Theoretical Gaps: Shared Blind Spots in Existing Paradigms
    - 1.3 CET's Core Contributions
    - 1.4 Methodology and Paper Structure

    **Chapter 2: Literature Review and Theoretical Foundations**

    - 2.1 Cognitive Offloading Research
    - 2.2 Critical Review of Extended Mind Theory
    - 2.3 Scaffolding Theory and Antifragility

    **Chapter 3: Core CET Theory Construction**

    - 3.0 Core Terminology and Anchor Definitions (B1-B5)
    - 3.1 In-depth Exposition of AVP Principle
    - 3.2 Beneficial Cognitive Friction Mechanism
    - 3.3 Systematic Support Reduction
    - 3.4 Partner-like Agency

    **Chapter 4: Cross-Scale Extensions**

    - 4.1 Team Level (T-AVP)
    - 4.2 Organizational Level (O-AVP)
    - 4.3 Societal Level (S-AVP)
    - 4.4 Unified Cross-Scale Mechanisms

    **Chapter 5: Technical Implementation: LSA Layered Architecture**

    - 5.1 LSA Four-Layer Architecture
    - 5.2 Cognitive Friction Engine (CFE)
    - 5.3 Support Graduation Scheduler (SGS)
    - 5.4 AVP Telemetry Module (AVP-TM)
    - 5.5 Multi-Scale Orchestrator (MSO)

    **Chapter 6: Limitations, Falsification Paths, and Future Directions**

    - 6.1 Six Major Limitations of the Theory
    - 6.2 Eight Falsifiable Hypotheses (H1-H8)
    - 6.3 Future Research Agenda

    **Appendices**

    - Core Terminology Glossary
    - Parameter Registry
    - Complete Case Study: Programming Education Platform

    **References**

    ------

    # Chapter 1: Introduction and Theoretical Positioning

    ## 1.1 Core Proposition: A New Standard for Evaluating AI

    **The true value of an AI tool lies not in how strong you are when using it, but in how strong you are when you unplug it.**

    We formalize this principle as the **Antifragility Validation Principle (AVP)**:

    > Validate collaboration through **Unplugged Test** to verify whether it promotes independent capability. Core criterion: **$P_2 \geq B_0 + \delta$**.
    >
    > Where: $B_0$ is the baseline capability before using AI, $P_2$ is independent performance within the unplugged window after collaboration ($W = 4\text{–}8$ weeks, default 6 weeks, working assumption), and $\delta$ is the minimum meaningful lift threshold ($\geq 0.3\,\mathrm{SD}$ or 10%, working assumption).

    This criterion reveals two fundamentally different AI usage paradigms:

    - **Cognitive Exoskeleton mode**: Independent performance significantly declines ($P_2 < B_0$), permanent AI dependency
    - **Cognitive Endosymbiosis mode**: Independent performance exceeds original level ($P_2 \geq B_0 + \delta$), AI use strengthens underlying capabilities

    Neuroscience has already provided warning signals: Dahmani et al. (2020) found significant associations between habitual GPS use and both spatial memory ability and hippocampal gray matter volume. Educational research indicates that heavy users of AI writing tools show declining fluency and structural organization in independent writing when assistance is removed. This negative effect of "cognitive offloading" has substantial empirical foundation (Risko & Gilbert, 2016; Sparrow et al., 2011).

    What is even more alarming is the **concealment** of this degradation. Users feel they are "progressing"—tasks are completed faster, output quality is higher—but this may mask systematic erosion of underlying cognitive architecture. When the perspective extends to the generational scale, a stark question emerges: **If mainstream AI usage patterns continue to follow "exoskeleton" logic, human society may face a new form of civilizational fragility—not because AI betrays us, but because we voluntarily abandon independent thinking capabilities.**

    ## 1.2 Theoretical Gaps: Shared Blind Spots in Existing Paradigms

    Current human-computer interaction research is dominated by three paradigms, none of which effectively address the challenges outlined above:

    **Tool paradigm**: Treats AI as a passive efficiency tool, ignoring the reverse shaping of cognitive patterns through long-term use.

    **Augmentation paradigm**: As exemplified by Engelbart's (1962) vision of "intelligence augmentation," assumes that "augmentation" is necessarily positive, lacking mechanisms to identify "negative cognitive enhancement effects." Extended Mind Theory (Clark & Chalmers, 1998), while acknowledging cognitive extension, fails to distinguish between **benign extension** (promoting growth) and **pathological extension** (leading to dependency).

    **Automation paradigm**: Focuses on AI replacing human tasks to maximize efficiency, with almost no consideration for long-term cognitive health.

    **The shared blind spot of these three paradigms**: All lack **operationalizable evaluation criteria** and **unified design principles** to judge the long-term health of human-AI collaboration.

    ## 1.3 CET's Core Contributions

    This study proposes the Cognitive Endosymbiosis Theory (CET), filling the theoretical gaps outlined above:

    ### 1.3.1 Evaluation Criterion: Antifragility Validation Principle (AVP)

    **AVP Operationalization**:

    - **Baseline measurement ($T_0$)**: Independent capability before using AI
    - **Collaboration measurement ($T_1$)**: Performance while collaborating with AI
    - **Post-unplugged measurement ($T_3$)**: Independent capability measured after the unplugged window ($W = 4\text{–}8$ weeks)

    **Judgment criteria**:

    - $P_2 \geq B_0 + \delta$: Success (Cognitive Endosymbiosis)
    - $P_2 \approx B_0$: Neutral (no harm caused but no growth promoted)
    - $P_2 < B_0$: Failure (Cognitive Exoskeleton)

    ### 1.3.2 Design Principles: Endosymbiotic Minimal Law (EML)

    > **Endosymbiotic Minimal Law (EML)**: The necessary design conditions for constituting "Cognitive Endosymbiosis" are:
    >
    > (1) **Beneficial Cognitive Friction**: Placing users in the optimal challenge zone (50$\text{–}$70% success rate, working assumption; individual adaptation required)
    >
    > (2) **Systematic Support Reduction**: AI support intensity gradually decreases from S4$\rightarrow$S1$\rightarrow$S0 according to a reduction curve
    >
    > These two constitute jointly sufficient design conditions, but ultimately still require **AVP ($P_2 \geq B_0 + \delta$) as the necessary acceptance criterion**.

    **Boundary conditions**: This theory applies to **capability-enhancing** human-AI collaboration; **compensatory exoskeletons** (such as disability assistance) are outside this framework. All parameters are **conceptual working models** requiring cross-domain calibration.

    ### 1.3.3 AI Role Reconstruction: Partner-like Agency

    Reshaping AI from a passive tool into a cognitive endosymbiont with **"Partner-like Agency"** (see §3.4; Term map), including three operationalizable anchors:

    1. **Friction injection**: AI proactively creates appropriate cognitive challenges
    2. **Scaffolding fadeout**: Follows systematic support reduction curve
    3. **AVP closed loop**: The endpoint of collaboration is user independent capability enhancement

    ### 1.3.4 Technical Implementation: Layered Symbiosis Architecture (LSA)

    > **LSA-F (Functional Layers)**: L1 Knowledge Integration | L2 State Modeling | L3 Friction Calibration | L4 Metacognitive Orchestration
    >
    > **Support Level Stack (S4$\rightarrow$S1$\rightarrow$S0)** expresses support intensity and is orthogonal to LSA-F.

    **Hard constraint: L1-L4 (functional layers) and S4-S0 (support intensity; S0 is unplugged/test-only) are orthogonal abstractions; do not substitute or interleave them within the same formalism.**

    **Cognitive Exoskeleton vs Cognitive Endosymbiosis Core Comparison**:

    | Dimension          | Cognitive Exoskeleton  | Cognitive Endosymbiosis         |
    | ------------------ | ---------------------- | ------------------------------- |
    | Design philosophy  | Replacement/offloading | Empowerment/strengthening       |
    | Cognitive friction | Minimized              | Optimized (50$\text{–}$70%)              |
    | Temporality        | Permanent dependency   | Time-limited symbiosis          |
    | Support reduction  | None/fixed support     | Systematic reduction (S4$\rightarrow$S1$\rightarrow$S0) |
    | AVP outcome        | $P_2 \leq B_0$         | $P_2 \geq B_0 + \delta$         |

    ### 1.3.5 Theoretical Positioning: Normative Solution Framework

    This study is positioned as a **normative solution framework**, not only diagnosing problems but also explicitly specifying **how human-AI collaboration should be constructed** to avoid dependency degradation. We provide:

    - **Construction standards** (through EML)
    - **Acceptance standards** (through AVP)
    - **Engineering paths** (through LSA)

    **Relationship to AI alignment research**: This theory complements AI alignment research—alignment research focuses on "whether AI intentions align with human values," while this theory focuses on "whether human-AI collaboration promotes sustainable development of human capabilities." In this sense, AVP-validated growth constitutes "cognitive resilience" under tool volatility.

    ## 1.4 Methodology and Paper Structure

    ### 1.4.1 Methodological Positioning

    This study employs a methodology **combining theory construction and conceptual analysis**, positioned as a **falsifiable theoretical framework**.

    **Transparency statement**:

    1. All quantitative parameters ($\delta \geq 0.3\,\mathrm{SD}$, 50$\text{–}$70% success rate, $W = 4\text{–}8$ weeks) are **conceptual working models**, based on reasonable inferences from cognitive psychology and educational measurement literature, requiring cross-domain calibration and empirical validation.
    2. Case selection follows the **theoretical enlightenment** criterion, not pursuing statistical representativeness, used to elucidate mechanisms and boundary conditions.
    3. We explicitly indicate theoretical applicability boundaries and falsification paths (detailed in Chapter 6), adhering to open science principles.

    ### 1.4.2 Paper Structure

    **Chapter 2**: Reviews cross-disciplinary evidence foundations (cognitive offloading, extended mind, scaffolding theory, antifragility)

    **Chapter 3**: Constructs the AVP/EML theoretical framework, clearly defines B1-B5 anchor definitions

    **Chapter 4**: Extends to team (T-AVP) and organizational (O-AVP) levels, discusses generational divide

    **Chapter 5**: Discusses LSA technical implementation paths (L1-L4 layered architecture)

    **Chapter 6**: Clarifies theoretical boundaries and proposes eight falsifiable hypotheses (H1-H8)

    ## 1.5 Terminology and Parameter Conventions

    This paper adopts the Single Source of Truth (SSOT) principle. All core terminology definitions are found in Section 3.0 of Chapter 3, and all parameter default values are found in Appendix B Parameter Registry. If discrepancies are found, these two sources take precedence. All deltas to SSOT will be recorded in the change-log and mirrored to CETG7.